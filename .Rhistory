labs(title="States with biggest changes in reading scores", subtitle="Change from 2019 to 2022", fill="Change in grade levels") +
theme_blank() +
theme(legend.position = 'right',
axis.text.x = element_blank(),
axis.text.y = element_blank(),
axis.ticks = element_blank(),
panel.grid.major = element_blank(),
legend.title = element_text())
ggplot(us_states) +
geom_sf(aes(fill=all_ela1922), color=NA) +
scale_fill_viridis() +
labs(title="States with biggest changes in reading scores", subtitle="Change from 2019 to 2022", fill="Change in grade levels")
ggplot(us_states) +
geom_sf(aes(fill=all_ela1922), color=NA) +
scale_fill_viridis()
#If you want to customize the look more:
ggplot(us_states) +
geom_sf(aes(fill=all_ela1922), color=NA) +
scale_fill_viridis() +
labs(title="States with biggest changes in reading scores", subtitle="Change from 2019 to 2022", fill='Change in grade levels') +
theme_ap() +
theme(legend.position = 'right',
axis.text.x = element_blank(),
axis.text.y = element_blank(),
axis.ticks = element_blank(),
panel.grid.major = element_blank(),
legend.title = element_text())
#library(ggrepel)
#library(cowplot)
library(aptheme)
ggplot(us_states) +
geom_sf(aes(fill=all_ela1922), color=NA) +
scale_fill_viridis() +
labs(title="States with biggest changes in reading scores", subtitle="Change from 2019 to 2022") +
theme_ap() +
theme(legend.position = 'right',
axis.text.x = element_blank(),
axis.text.y = element_blank(),
axis.ticks = element_blank(),
panel.grid.major = element_blank(),
legend.title = element_text()) +
labs(fill='Change in grade levels')
reading_changes = ggplot(us_states) +
geom_sf(aes(fill=all_ela1922), color=NA) +
scale_fill_viridis() +
labs(title="States with biggest changes in reading scores", subtitle="Change from 2019 to 2022", fill='Change in grade levels')
reading_changes
#If you want to customize the look more:
reading_changes +
theme_ap() +
theme(legend.position = 'right',
axis.text.x = element_blank(),
axis.text.y = element_blank(),
axis.ticks = element_blank(),
panel.grid.major = element_blank(),
legend.title = element_text()) +
labs(fill='Change in grade levels')
reading_changes = ggplot(us_states) +
geom_sf(aes(fill=all_ela1922), color=NA) +
scale_fill_viridis() +
labs(title="States with biggest changes in reading scores", subtitle="Change from 2019 to 2022", fill='Change in grade levels')
reading_changes
#If you want to customize the look more:
reading_changes +
theme_ap() +
theme(legend.position = 'right',
axis.text.x = element_blank(),
axis.text.y = element_blank(),
axis.ticks = element_blank(),
panel.grid.major = element_blank(),
legend.title = element_text()) +
labs(fill='Change in grade levels')
ggplot(us_states) +
geom_sf(aes(fill=b_ela1922), color=NA) +
theme_void() +
scale_fill_viridis() +
labs(title="States with biggest changes in reading scores for Black students")
#Map states with the biggest changes in reading scores for Black students
ggplot(us_states) +
geom_sf(aes(fill=b_ela1922), color=NA) +
theme_void() +
scale_fill_viridis() +
labs(title="States with biggest changes in reading scores for Black students")
#Map states with the biggest changes in reading/math scores for Black/Hispanic students
ggplot(us_states) +
geom_sf(aes(fill=b_ela1922), color=NA) +
theme_void() +
scale_fill_viridis() +
labs(title="States with biggest changes in reading scores for Black students")
ggplot(us_states) +
geom_sf(aes(fill=h_ela1922), color=NA) +
theme_void() +
scale_fill_viridis() +
labs(title="States with biggest changes in reading scores for Hispanic students")
ggplot(us_states) +
geom_sf(aes(fill=all_mth1922), color=NA) +
theme_void() +
scale_fill_viridis() +
labs(title="States with biggest changes in math scores")
ggplot(us_states) +
geom_sf(aes(fill=b_mth1922), color=NA) +
theme_void() +
scale_fill_viridis() +
labs(title="States with biggest changes in math scores for Black students")
ggplot(us_states) +
geom_sf(aes(fill=h_mth1922), color=NA) +
theme_void() +
scale_fill_viridis() +
labs(title="States with biggest changes in math scores for Hispanic students")
districts = read_csv("./data/district_learning_loss_data.csv")
us_districts <- school_districts(cb = TRUE) %>%
shift_geometry() %>% ms_simplify(keep = 0.001)
#library(corrplot)
library(rmapshaper)
us_districts <- school_districts(cb = TRUE) %>%
shift_geometry() %>% ms_simplify(keep = 0.001)
us_districts_elem <- school_districts(cb = TRUE, type="elementary") %>%
ms_simplify(keep = 0.001)
us_districts_sec <- school_districts(cb = TRUE, type="secondary") %>%
ms_simplify(keep = 0.001)
us_districts = left_join(us_districts, districts, by=c("GEOID"="id"))
us_districts_elem = left_join(us_districts_elem, districts, by=c("GEOID"="id"))
us_districts_sec = left_join(us_districts_sec, districts, by=c("GEOID"="id"))
ggplot() +
geom_sf(data=us_districts, aes(fill=all_ela1922), color=NA) +
geom_sf(data=us_districts_elem, aes(fill=all_ela1922), color=NA) +
geom_sf(data=us_districts_sec, aes(fill=all_ela1922), color=NA) +
scale_fill_viridis() +
labs(title="Districts in the U.S. with biggest changes in reading scores") +
theme_bw()
ggplot() +
geom_sf(data=us_districts, aes(fill=all_mth1922), color=NA) +
geom_sf(data=us_districts_elem, aes(fill=all_mth1922), color=NA) +
geom_sf(data=us_districts_sec, aes(fill=all_mth1922), color=NA) +
scale_fill_viridis() +
labs(title="Districts in the U.S. with biggest changes in math scores") +
theme_bw()
al_districts <- school_districts(cb = TRUE, state="AL")
al_districts = left_join(al_districts, districts, by=c("GEOID"="id"))
df = al_districts %>% select(STATEFP:name, all_ela1922, all_ela1922_e, all_mth1922, all_mth1922_e, b_ela1922, b_ela1922_e, b_mth1922, b_mth1922_e, h_ela1922, h_ela1922_e, b_mth1922, b_mth1922_e, perfrl, pct_remote, esser_per_student)
ggplot(al_districts) +
geom_sf(aes(fill=all_ela1922), color=NA) +
theme_void() +
scale_fill_viridis() +
labs(title="Districts in Alabama with biggest changes in reading scores")
ggplot(al_districts) +
geom_sf(aes(fill=b_ela1922), color=NA) +
theme_void() +
scale_fill_viridis() +
labs(title="Districts with biggest changes in Black reading")
ggplot(al_districts) +
geom_sf(aes(fill=h_ela1922), color=NA) +
theme_void() +
scale_fill_viridis() +
labs(title="Districts in Alabama with biggest changes in reading scores for Hispanic students") +
geom_text(data=subset(al_districts, h_ela1922>0.4 | h_ela1922 < -0.4), aes(lon, lat, label = LEA_NAME))
ggplot(al_districts) +
geom_sf(aes(fill=h_ela1922), color=NA) +
theme_void() +
scale_fill_viridis() +
labs(title="Districts in Alabama with biggest changes in reading scores for Hispanic students")
library(sf)
starwars <- read_html("https://rvest.tidyverse.org/articles/starwars.html")
#We can use rvest which is part of the tidyverse
library(rvest)
house <- read_html("https://www.legis.ga.gov/members/house")
house
house %>% html_elements("table")
house %>% html_table()
house %>% html_table() %>% View()
house %>% html_elemet(".table table-striped sortable memberlist") %>%
html_table()
house %>% html_element(".table table-striped sortable memberlist") %>%
html_table()
house %>% html_element(".memberlist") %>%
html_table()
house %>% html_element(".memberlist")
house %>% html_element(".table-responsive")
house
house %>% html_nodes(.memberlist)
house %>% html_nodes(".memberlist")
house %>% html_nodes(".table table-striped sortable memberList")
house %>% html_nodes(".table")
house %>% html_nodes(".table")[1]
house %>% html_nodes(".table")
house %>% html_nodes(".pageContent")
house %>% html_table(fill=TRUE)
tables = house %>% html_table(fill=TRUE)
tables
tables[1]
tables[2]
tables[[1]]
class(house)
house %>% html_elements("table")
house %>% html_elements("p")
house <- read_html("https://www.legis.ga.gov/members/house")
house %>% html_elements("td")
house %>% html_elements("tr")
house %>% html_elements("thead")
html <- minimal_html("<body>
<p>
This is
a
paragraph.</p><p>This is another paragraph.
It has two sentences.</p>
")
html %>% html_elements("p")
house %>%
html_node("table") %>%
html_table()
url <- 'https://www.sports-reference.com/cbb/schools/bethune-cookman/2020-schedule.html'
schedule <- url %>% read_html %>%  html_node('table#schedule') %>% html_table()
schedule
url <- 'https://www.legis.ga.gov/members/house'
schedule <- url %>% read_html %>%  html_node('table') %>% html_table()
schedule <- url %>% read_html
schedule %>% html_node('table')
library(RSelenium)
install.packages('RSelenium')
library(RSelenium)
url <- 'https://www.legis.ga.gov/members/house'
RSelenium::startServer()
driver <- rsDriver(browser = c("chrome", "firefox"), verbose = TRUE)
driver <- rsDriver(browser = "chrome", verbose = TRUE)
remDr <- driver[["client"]]
remDr$navigate(url)
url <- 'https://www.legis.ga.gov/members/house'
remDr$navigate(url)
remDr$navigate('https://www.legis.ga.gov/members/house')
url <- 'https://www.legis.ga.gov/members/house'
checkForServer()
schedule <- url %>% read_html
schedule %>% html_node('//td')
binman::list_versions(“chromedriver”)
list_versions("chromedriver")
library(RSelenium)
list_versions("chromedriver")
page = read_html(url)
page
page[1]
page[2]
page[2] %>% html_elements("body")
page[2] %>% html_element("body")
page[2] %>% html_nodes("td")
page %>%
html_element("table") %>%
html_table()
page %>%
html_nodes(xpath = '//table') %>%
html_table()
page %>%
html_nodes(xpath = '//table') %>%
html_table() %>% View()
url <- 'https://www.legis.ga.gov/members/house'
page = read_html(url)
page %>%
html_element("table") %>%
html_table() %>% View()
tables <- html_nodes(page, "table")
tables
View(tables)
rdriver <- rsDriver(browser = "chrome",
port = 2122L,
chromever  = "109.0.5414.119",
)
rdriver <- rsDriver(browser = "chrome",
port = 2122L,
chromever  = "109.0.5414.25",
)
#library(RSelenium)
install.packages("splashr")
library(splashr)
library(splashr)
install.packages("splashr")
install.packages("splashr", repos = c("https://cinc.rud.is/"))
library(RSelenium)
rD <- rsDriver() # runs a chrome browser, wait for necessary files to download
rD = rsDriver(browser="chrome", port=4234L, chromever="109.0.5414.74")
library(wdman)
selServ <- wdman::selenium(verbose = FALSE)
selServ$log()
rD = rsDriver(browser="chrome", port=4234L, chromever="109.0.5414.74")
selServ <- wdman::selenium(verbose = FALSE)
selServ$log()
library(rvest)
url <- 'https://www.legis.ga.gov/members/house'
page = read_html(url)
page %>%
html_element("table") %>%
html_table()
install.packages("splashr")
r.version
install.packages("purrr")
library(dplyr)
library(stringr)
library(purrr)
library(rvest)
library(RSelenium)
rD <- RSelenium::rsDriver()
# Get Chrome version
system2(command = "wmic",
args = 'datafile where name="C:\\\\Program Files (x86)\\\\Google\\\\Chrome\\\\Application\\\\chrome.exe" get Version /value')
# Get Chrome version
system2(command = "wmic",
args = 'datafile where name="C:\\\\Program Files (x86)\\\\Google\\\\Chrome\\\\Application\\\\chrome.exe" get Version /value')
binman::list_versions(appname = "chromedriver")
# Start Selenium server and browser
rD <- RSelenium::rsDriver(browser = "chrome",
chromever = "109.0.5414.25")
# Start Selenium server and browser
rD <- RSelenium::rsDriver(browser = "chrome",
chromever = "109.0.5414.74")
# Start Selenium server and browser
rD <- RSelenium::rsDriver(browser = "chrome",
chromever = "109.0.5414.74")
selServ <- wdman::selenium(verbose = FALSE)
selServ$log()
library(httr2)
install.packages("httr2")
library(httr2)
library(tidyverse)
"https://www.legis.ga.gov/api/members/list/1031?chamber=1" %>%
request() %>%
req_auth_bearer_token("eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJuYmYiOjE2NzU3OTY4NDgsImV4cCI6MTY3NTc5NzE0OCwiaWF0IjoxNjc1Nzk2ODQ4fQ.3pxxIurHe8uPgXGY0DZay0wAUk8Lf5rbHsGvXiNbYMY") %>%
req_perform() %>%
resp_body_json(simplifyVector = TRUE) %>%
as_tibble()
library(rvest)
page = read_html(url)
library(httr)
library(jsonlite)
res = GET("https://api.open-notify.org/astros.json")
res = GET("https://www.legis.ga.gov/api/members/list/1031?chamber=1")
res
rawToChar(res$content)
library(jsonlite)
house = fromJSON("./data/georgia_house.json")
View(house)
str(house)
View(house[[6]][[1]])
#install.packages("jsonlite")
library(jsonlite)
house = fromJSON("./data/georgia_house.json")
str(house)
View(house)
house %>% unnest()
house %>% unnest(cols = c(district, photos, name, districtAddress))
house
View(csv)
View(house)
url = "https://rptsvr1.tea.texas.gov/cgi/sas/broker?_service=marykay&_program=sfadhoc.budget_report_2022.sas&_service=appserv&_debug=0&who_box=&who_list=101912"
library(rvest)
tables <- html_nodes(url, "table")
tables <- html_elements(url, "table")
url = read_html("https://rptsvr1.tea.texas.gov/cgi/sas/broker?_service=marykay&_program=sfadhoc.budget_report_2022.sas&_service=appserv&_debug=0&who_box=&who_list=101912")
tables <- html_nodes(url, "table")
tables
tables[1]
tables <- html_nodes(url, "table") %>%
html_tables(fill=TRUE)
tables <- html_nodes(url, "table") %>%
html_table(fill=TRUE)
tables
tables[1]
tables[1] %>% View()
tables[[1]] %>% View()
tables[[2]] %>% View()
tables[[3]] %>% View()
tables[[2]]
tables[[2]] %>%
View()
budget = tables[[2]] %>%
View()
tables[[2]] %>%
View()
budget = tables[[2]]
colnames(budget) = c("category","gender_fund","gender_fund_pct", "general_fund_per_student", "all_funds", "all_funds_percent", "all_funds_per_student")
View(budget)
colnames(budget) = c("category","gen_fund","gen_fund_pct", "general_fund_per_student", "all_funds", "all_funds_percent", "all_funds_per_student")
tables <- html_nodes(url, "table")
View(tables[[2]])
xml_child(tables[[2]], 3)
webpage = read_html("https://rptsvr1.tea.texas.gov/cgi/sas/broker?_service=marykay&_program=sfadhoc.budget_report_2022.sas&_service=appserv&_debug=0&who_box=&who_list=101912")
webpage %>%
html_elements("tbody") %>%
html_table()
webpage = read_html("https://rptsvr1.tea.texas.gov/cgi/sas/broker?_service=marykay&_program=sfadhoc.budget_report_2022.sas&_service=appserv&_debug=0&who_box=&who_list=101912")
#If the tables on this page were tidy, the code to scrape them would be very simple.
tables <- html_nodes(webpage, "table") %>%
html_table()
budget = tables[[2]]
View(budget)
colnames(budget) = c("category","gender_fund","gender_fund_pct", "general_fund_per_student", "all_funds", "all_funds_percent", "all_funds_per_student")
#The table has rows that span multiple columns, which make the resulting output messy. I will leave it as an exercise to you to clean it up.
colnames(budget) = c("category","gen_fund","gen_fund_pct", "gen_fund_per_student", "all_funds", "all_funds_percent", "all_funds_per_student")
View(budget)
webpage = read_html(url)
url = "https://rptsvr1.tea.texas.gov/cgi/sas/broker?_service=marykay&_program=sfadhoc.budget_report_2022.sas&_service=appserv&_debug=0&who_box=&who_list=101912"
webpage = read_html(url)
#If the tables on this page were tidy, the code to scrape them would be very simple.
tables <- html_nodes(webpage, "table") %>%
html_table()
budget = tables[[2]]
View(budget)
str_extract(url, "who_list=.+")
str_sub(url, start= -6)
str_sub(url, start= -7)
str_sub(url, start= -6)
budget$district_code = str_sub(url, start= -6)
View(budget)
district_codes = c("101912", "057905", "031901")
tea_scrape = function(district_code) {
url = paste0("https://rptsvr1.tea.texas.gov/cgi/sas/broker?_service=marykay&_program=sfadhoc.budget_report_2022.sas&_service=appserv&_debug=0&who_box=&who_list=", district_code)
print(paste0,"scraping ", url)
webpage = read_html(url)
tables <- html_nodes(webpage, "table") %>%
html_table()
budget = tables[[2]]
colnames(budget) = c("category","gen_fund","gen_fund_pct", "gen_fund_per_student", "all_funds", "all_funds_percent", "all_funds_per_student")
budget$district_code = str_sub(url, start= -6)
Sys.sleep(3)
return(budget)
}
tea_scrape(district_code[2])
tea_scrape(district_codes[2])
district_codes[2]
for (district_code in district_codes) {
url = paste0("https://rptsvr1.tea.texas.gov/cgi/sas/broker?_service=marykay&_program=sfadhoc.budget_report_2022.sas&_service=appserv&_debug=0&who_box=&who_list=", district_code)
print(paste0,"scraping ", url)
}
district_codes = c("101912", "057905", "031901")
district_codes
for (district_code in district_codes) {
url = paste0("https://rptsvr1.tea.texas.gov/cgi/sas/broker?_service=marykay&_program=sfadhoc.budget_report_2022.sas&_service=appserv&_debug=0&who_box=&who_list=", district_code)
print(paste0,"scraping ", url)
}
for (district_code in district_codes) {
print(district_code)
url = paste0("https://rptsvr1.tea.texas.gov/cgi/sas/broker?_service=marykay&_program=sfadhoc.budget_report_2022.sas&_service=appserv&_debug=0&who_box=&who_list=", district_code)
print(paste0("scraping ", url))
}
tea_scrape = function(district_code) {
url = paste0("https://rptsvr1.tea.texas.gov/cgi/sas/broker?_service=marykay&_program=sfadhoc.budget_report_2022.sas&_service=appserv&_debug=0&who_box=&who_list=", district_code)
print(paste0("scraping ", url))
webpage = read_html(url)
tables <- html_nodes(webpage, "table") %>%
html_table()
budget = tables[[2]]
colnames(budget) = c("category","gen_fund","gen_fund_pct", "gen_fund_per_student", "all_funds", "all_funds_percent", "all_funds_per_student")
budget$district_code = str_sub(url, start= -6)
Sys.sleep(3)
return(budget)
}
tea_scrape(district_codes[2])
all_budgets = data.frame()
for (district_code in district_codes) {
budget = tea_scrape(district_code)
all_budgets = rbind(all_budgets, budget)
}
all_budgets = data.frame()
count = 1
for (district_code in district_codes) {
print(count)
budget = tea_scrape(district_code)
all_budgets = rbind(all_budgets, budget)
count = count + 1
}
all_budgets = data.frame()
all_budgets = data.frame()
count = 1
for (district_code in district_codes) {
print(count)
budget = tea_scrape(district_code)
all_budgets = rbind(all_budgets, budget)
count = count + 1
}
all_budgets %>% View()
View(all_budgets)
url = "https://rptsvr1.tea.texas.gov/cgi/sas/broker?_service=marykay&_program=sfadhoc.budget_report_2022.sas&_service=appserv&_debug=0&who_box=&who_list=101912"
webpage = read_html(url)
tables <- html_nodes(webpage, "table") %>%
html_table()
url = "https://rptsvr1.tea.texas.gov/cgi/sas/broker?_service=marykay&_program=sfadhoc.budget_report_2022.sas&_service=appserv&_debug=0&who_box=&who_list=101912"
webpage = read_html(url) #Read the HTML, the code that makes up the webpage
tables <- html_nodes(webpage, "table") %>% #Search for all "table" elements in the HTML
html_table() #Turn those tables into dataframes
budget = tables[[2]] #The scraper found three tables; we only need the 2nd
View(budget)
#The table has rows that span multiple columns, which make the resulting output messy. I will leave it as an exercise to you to clean it up fully. For now I'll just fix the columns and also add a column with the district code.
colnames(budget) = c("category","gen_fund","gen_fund_pct", "gen_fund_per_student", "all_funds", "all_funds_percent", "all_funds_per_student")
budget$district_code = str_sub(url, start= -6) #Grab the last six digits of the URL
tea_scrape = function(district_code) {
url = paste0("https://rptsvr1.tea.texas.gov/cgi/sas/broker?_service=marykay&_program=sfadhoc.budget_report_2022.sas&_service=appserv&_debug=0&who_box=&who_list=", district_code)
print(paste0("scraping ", url))
webpage = read_html(url)
tables <- html_nodes(webpage, "table") %>%
html_table()
budget = tables[[2]]
colnames(budget) = c("category","gen_fund","gen_fund_pct", "gen_fund_per_student", "all_funds", "all_funds_percent", "all_funds_per_student")
budget$district_code = str_sub(url, start= -6)
Sys.sleep(3) #Pause for three seconds to avoid overloading the server
return(budget)
}
district_codes = c("101912", "057905", "031901")
all_budgets = data.frame()
count = 1
for (district_code in district_codes) {
print(count)
budget = tea_scrape(district_code)
all_budgets = rbind(all_budgets, budget)
count = count + 1
}
